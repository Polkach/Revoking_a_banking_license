{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая вырезает html синтаксис из строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def html_stripper(text):\n",
    "    return re.sub('<[^<]+?>', '', str(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получает число страниц для данного показателя на сайте banki.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_max_page(page):\n",
    "    max_page = html_stripper(page.find('span',attrs={'data-bind':'total-items'}))\n",
    "    if max_page=='None':\n",
    "        return 0\n",
    "    else:\n",
    "        return int((int(max_page)-1)/50)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получает номера лицензий со значениями со страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_values(page):\n",
    "    licens = page.findAll('div',attrs={'class':'font-size-small color-gray-burn'})\n",
    "    licens = html_stripper(licens)\n",
    "    licens = re.split('№ |,',licens)\n",
    "    values = page.findAll('td',attrs={'class':'text-align-right'})\n",
    "    zap = {}\n",
    "    for i in range(int(len(licens)/3)):\n",
    "        zap.update({licens[1+i*3]:int(re.sub('−','-',re.sub(' |\\n|,','',html_stripper(values[4*i]))))})\n",
    "    return zap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Массив доступных дат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = []\n",
    "for year in range(2008,2018):\n",
    "    for month in range(1,13):\n",
    "        if month>=10:\n",
    "            dates.append(str(year)+'-'+str(month)+'-01')\n",
    "        else:\n",
    "            dates.append(str(year)+'-0'+str(month)+'-01')\n",
    "dates = dates[2:-9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Массив названий фичей и их номеров для ссылки (предварительно сохранил код всплывающего окна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open('features', 'r')\n",
    "page = file.read()\n",
    "file.close()\n",
    "page = BeautifulSoup(page, 'lxml')\n",
    "features = page.findAll('a',attrs={'class':'rating-parameter-list--item__link active'})\n",
    "names = html_stripper(features)\n",
    "IDS = re.split('PROPERTY_ID=|\">',str(features))\n",
    "names = re.split('                                                    |                                                |                                            ',names)\n",
    "d = {}\n",
    "for i in range(1,173,2):\n",
    "    d.update({IDS[i]:names[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем наименее информативные показатели и дублирующиеся показатели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.pop('10')\n",
    "d.pop('210')\n",
    "d.pop('220')\n",
    "d.pop('230')\n",
    "d.pop('240')\n",
    "d.pop('310')\n",
    "d.pop('320')\n",
    "d.pop('330')\n",
    "d.pop('340')\n",
    "d.pop('420')\n",
    "d.pop('421')\n",
    "d.pop('430')\n",
    "d.pop('431')\n",
    "d.pop('440')\n",
    "d.pop('441')\n",
    "d.pop('450')\n",
    "d.pop('451')\n",
    "d.pop('460')\n",
    "d.pop('461')\n",
    "d.pop('520')\n",
    "d.pop('521')\n",
    "d.pop('530')\n",
    "d.pop('531')\n",
    "d.pop('540')\n",
    "d.pop('541')\n",
    "d.pop('550')\n",
    "d.pop('551')\n",
    "d.pop('560')\n",
    "d.pop('561')\n",
    "d.pop('20')\n",
    "d.pop('25')\n",
    "d.pop('30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого месяца создаем таблицу со всеми показателями всех банков в этот месяц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for date in ['2016-04-01']:\n",
    "    print(date)\n",
    "    \n",
    "    stat_id='100'\n",
    "    url = 'http://www.banki.ru/banks/ratings/?SEARCH_NAME=&SEARCH_REGN=&search%5Btype%5D=name&sort_param=rating&sort_order=ASC&PROPERTY_ID='\n",
    "    url += stat_id + '&REGION_ID=0&date1='\n",
    "    url += date + '&date2=2016-12-01&IS_SHOW_GROUP=0&IS_SHOW_LIABILITIES=0#search_label'\n",
    "    page = requests.get(url)\n",
    "    page = page.content\n",
    "    page = BeautifulSoup(page, 'lxml')\n",
    "    max_page = get_max_page(page)\n",
    "\n",
    "    tabl = {}\n",
    "    tabl.update(get_values(page))\n",
    "\n",
    "    for i in range(2,max_page+1):\n",
    "        url = 'http://www.banki.ru/banks/ratings/?PAGEN_1=' + str(i)\n",
    "        url += '&search[type]=name&sort_param=rating&sort_order=ASC&PROPERTY_ID='\n",
    "        url += stat_id + '&REGION_ID=0&date1='\n",
    "        url += date + '&date2=2016-12-01&IS_SHOW_GROUP=0&IS_SHOW_LIABILITIES=0#search_label'\n",
    "        page = requests.get(url)\n",
    "        page = page.content\n",
    "        page = BeautifulSoup(page, 'lxml')\n",
    "        tabl.update(get_values(page))\n",
    "\n",
    "    base = pd.DataFrame(tabl,index=[int(stat_id)])\n",
    "\n",
    "    for stat_id in list(d.keys()):\n",
    "        \n",
    "        if int(stat_id)%100==0:\n",
    "            print(stat_id)\n",
    "        \n",
    "        if stat_id=='100':\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            url = 'http://www.banki.ru/banks/ratings/?SEARCH_NAME=&SEARCH_REGN=&search%5Btype%5D=name&sort_param=rating&sort_order=ASC&PROPERTY_ID='\n",
    "            url += stat_id + '&REGION_ID=0&date1='\n",
    "            url += date + '&date2=2016-12-01&IS_SHOW_GROUP=0&IS_SHOW_LIABILITIES=0#search_label'\n",
    "            page = requests.get(url)\n",
    "            page = page.content\n",
    "            page = BeautifulSoup(page, 'lxml')\n",
    "            max_page = get_max_page(page)\n",
    "\n",
    "            tabl = {}\n",
    "            tabl.update(get_values(page))\n",
    "\n",
    "            for i in range(2,max_page+1):\n",
    "                url = 'http://www.banki.ru/banks/ratings/?PAGEN_1=' + str(i)\n",
    "                url += '&search[type]=name&sort_param=rating&sort_order=ASC&PROPERTY_ID='\n",
    "                url += stat_id + '&REGION_ID=0&date1='\n",
    "                url += date + '&date2=2016-12-01&IS_SHOW_GROUP=0&IS_SHOW_LIABILITIES=0#search_label'\n",
    "                page = requests.get(url)\n",
    "                page = page.content\n",
    "                page = BeautifulSoup(page, 'lxml')\n",
    "                tabl.update(get_values(page))\n",
    "\n",
    "            base = base.append(pd.DataFrame(tabl,index=[int(stat_id)]))\n",
    "\n",
    "    base.to_csv(date+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь парсим историю макроэкономических показателей с сайта rbc.ru. Я не смог быстро разобраться, как парсить всплывающие окна, поэтому просто сохранил коды всплывающих окон в файлы (в этих окнах как раз история)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def macro(num):\n",
    "    file = open(str(num), 'r')\n",
    "    page = file.read()\n",
    "    file.close()\n",
    "    page = BeautifulSoup(page, 'lxml')\n",
    "    features = page.findAll('span',attrs={'class':'macro__indicators__chart__inner'})\n",
    "    tabl = {'month':int(re.sub(',','.',re.sub('\\n| ','',html_stripper(features[6])))[3:5]),\n",
    "            'year':int(re.sub(',','.',re.sub('\\n| ','',html_stripper(features[6])))[6:]),\n",
    "            'time':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[0]))),\n",
    "            'value':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[1]))),\n",
    "            'change':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[2]))),\n",
    "            'MOM':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[3]))),\n",
    "            'QOQ':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[4]))),\n",
    "            'YOY':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[5])))}\n",
    "    base = pd.DataFrame(tabl,index=[0])\n",
    "    for i in range(1,int(len(features)/7)):\n",
    "        tabl = {'month':int(re.sub(',','.',re.sub('\\n| ','',html_stripper(features[6+7*i])))[3:5]),\n",
    "                'year':int(re.sub(',','.',re.sub('\\n| ','',html_stripper(features[6+7*i])))[6:]),\n",
    "                'time':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[7*i]))),\n",
    "                'value':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[1+7*i]))),\n",
    "                'change':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[2+7*i]))),\n",
    "                'MOM':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[3+7*i]))),\n",
    "                'QOQ':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[4+7*i]))),\n",
    "                'YOY':re.sub(',','.',re.sub('\\n| ','',html_stripper(features[5+7*i])))}\n",
    "        base = base.append(pd.DataFrame(tabl,index=[i]))\n",
    "        \n",
    "    base = base[(base['year']>2008) | ((base['year']==2008) & (base['month']>=3))]\n",
    "    base.drop_duplicates(inplace=True,keep='first',subset='time')\n",
    "    if num not in [7,8]:\n",
    "        del base['MOM']\n",
    "        del base['QOQ']\n",
    "        del base['YOY']\n",
    "        del base['change']\n",
    "    else:\n",
    "        base['value'] = base['MOM']\n",
    "        del base['MOM']\n",
    "        del base['QOQ']\n",
    "        del base['YOY']\n",
    "        del base['change']\n",
    "    base.to_csv(str(num)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собсвтенно, обрабатываем эти файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(24):\n",
    "    macro(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем столбцы с месяцем и годом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = [3,2,1]+[12,11,10,9,8,7,6,5,4,3,2,1]*8+[12,11,10,9,8,7,6,5,4,3]\n",
    "Y = [2017]*3+[2016]*12+[2015]*12+[2014]*12+[2013]*12+[2012]*12+[2011]*12+[2010]*12+[2009]*12+[2008]*10\n",
    "base = pd.read_csv('0.csv')\n",
    "base['month'] = M\n",
    "base['year'] = Y\n",
    "del base['time']\n",
    "for i in range(1,20):\n",
    "    base2 = pd.read_csv(str(i)+'.csv')\n",
    "    base['value'+str(i)] = base2['value']\n",
    "base.to_csv('macro.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где-то нашел историю курса рубля к доллару"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kurs = pd.read_csv('usd_quotes.csv',sep=';')[:2300]\n",
    "kurs['day'] = 0\n",
    "kurs['month'] = 0\n",
    "kurs['year'] = 0\n",
    "for i in range(2300):\n",
    "    kurs['year'][i], kurs['month'][i], kurs['day'][i], = kurs['updated'][i].split('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем столбец курса рубля к макрокономическим показателям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tend = kurs.drop_duplicates(keep='last',subset=['month','year'])\n",
    "tend = tend.reset_index(drop=True)\n",
    "tend = tend[:-1]\n",
    "base['kurs'] = tend['price']\n",
    "base.to_csv('macro.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
