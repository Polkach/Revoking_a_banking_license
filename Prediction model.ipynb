{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.utils.np_utils as kutils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,GRU,SimpleR\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем таблицы банков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "banks = {}\n",
    "for fname in sorted(os.listdir('data2')):\n",
    "    banks[int(fname[:-4])] = pd.read_csv('data2/'+fname,encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отбираем в массивы номера лицензий закрывших банков и поныне работающих"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "work = []\n",
    "close = []\n",
    "for i in banks.keys():\n",
    "    if banks[i]['y7'][len(banks[i])-1]==-1:\n",
    "        work.append(i)\n",
    "        banks[i]['y8'] = 1+2*banks[i]['y7']\n",
    "    else:\n",
    "        close.append(i)\n",
    "        banks[i]['y8'] = 1 - banks[i]['y7']\n",
    "        banks[i]['y7'] -= banks[i]['y6']\n",
    "        banks[i]['y6'] -= banks[i]['y5']\n",
    "        banks[i]['y5'] -= banks[i]['y4']\n",
    "        banks[i]['y4'] -= banks[i]['y3']\n",
    "        banks[i]['y3'] -= banks[i]['y2']\n",
    "        banks[i]['y2'] -= banks[i]['y1']\n",
    "        banks[i]['y1'] -= banks[i]['y0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убираем банки, для которых нет наблюдений со всеми известными целевыми переменными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short = []\n",
    "for i in work:\n",
    "    if len(banks[i])<36:\n",
    "        banks.pop(i)\n",
    "        short.append(i)\n",
    "    else:\n",
    "        banks[i] = banks[i][:-35]\n",
    "for i in short:\n",
    "    work.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забираем целевые переменные в отдельные таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "razmetka = {}\n",
    "for i in banks.keys():\n",
    "    razmetka[i] = banks[i][['y'+str(j) for j in range(9)]]\n",
    "    for k in ['y'+str(j) for j in range(9)]:\n",
    "        del banks[i][k]\n",
    "    del banks[i]['year']\n",
    "    del banks[i]['month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем на тренировочную и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "work_train, work_test = train_test_split(work,test_size=0.2,random_state=12)\n",
    "close_train, close_test = train_test_split(close,test_size=0.2,random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аккуратно все группируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = {}\n",
    "test = {}\n",
    "train_y = {}\n",
    "test_y = {}\n",
    "for i in banks.keys():\n",
    "    if (i in work_train) or (i in close_train):\n",
    "        train[i] = banks[i]\n",
    "        train_y[i] = razmetka[i]\n",
    "    else:\n",
    "        test[i] = banks[i]\n",
    "        test_y[i] = razmetka[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем матожидание каждого признака и его дисперсию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E = {}\n",
    "D = {}\n",
    "N = 0\n",
    "for i in banks[1].columns:\n",
    "    E[i] = 0\n",
    "    D[i] = 0\n",
    "for i in train.keys():\n",
    "    for j in banks[1].columns:\n",
    "        E[j] += np.sum(banks[i][j])\n",
    "        D[j] += np.sum(banks[i][j]**2)\n",
    "    N += len(banks[i])\n",
    "for i in banks[1].columns:\n",
    "    E[i] = E[i]/N\n",
    "    D[i] = D[i]/N - E[i]**2\n",
    "    D[i] = D[i]**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартизируем распределения признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in train.keys():\n",
    "    for j in banks[1].columns:\n",
    "        train[i][j] = (train[i][j]-E[j])/D[j]\n",
    "for i in test.keys():\n",
    "    for j in banks[1].columns:\n",
    "        test[i][j] = (test[i][j]-E[j])/D[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переводим таблицы в numpy массивы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in train.keys():\n",
    "    train[i] = train[i].values.reshape(train[i].values.shape[0],1,train[i].values.shape[1])\n",
    "for i in test.keys():\n",
    "    test[i] = test[i].values.reshape(test[i].values.shape[0],1,test[i].values.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим целевую переменню в формат, пригодны для keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in train.keys():\n",
    "    train_y[i] = train_y[i]['y1']+2*train_y[i]['y2']+3*train_y[i]['y3']+4*train_y[i]['y4']+5*train_y[i]['y5']+6*train_y[i]['y6']+7*train_y[i]['y7']+8*train_y[i]['y8']\n",
    "    train_y[i] = kutils.to_categorical(train_y[i])\n",
    "for i in test.keys():\n",
    "    test_y[i] = test_y[i]['y1']+2*test_y[i]['y2']+3*test_y[i]['y3']+4*test_y[i]['y4']+5*test_y[i]['y5']+6*test_y[i]['y6']+7*test_y[i]['y7']+8*test_y[i]['y8']\n",
    "    test_y[i] = kutils.to_categorical(test_y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Форматируем, чтобы для каждого банка было одно число целевых дамми-переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in train.keys():\n",
    "    if train_y[i].shape[1]<9:\n",
    "        train_y[i] = np.hstack((train_y[i],np.zeros((train_y[i].shape[0],9-train_y[i].shape[1]))))\n",
    "for i in test.keys():\n",
    "    if test_y[i].shape[1]<9:\n",
    "        test_y[i] = np.hstack((test_y[i],np.zeros((test_y[i].shape[0],9-test_y[i].shape[1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число признаков и классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_num = train[1003].shape[2]\n",
    "class_num = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем F1-меру и более лояльную F1-меру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmera(pred,orig):\n",
    "    pres = 0\n",
    "    rec = 0\n",
    "    for i in range(9):\n",
    "        if sum((pred==i))!=0:\n",
    "            pres += sum((pred==i) & (orig==i)) / sum((pred==i))\n",
    "        rec += sum((pred==i) & (orig==i)) / sum((orig==i))\n",
    "    pres = pres/9\n",
    "    rec = rec/9\n",
    "    return 2*pres*rec/(pres+rec)\n",
    "def fmera_mode(pred,orig):\n",
    "    pres = 0\n",
    "    rec = 0\n",
    "    for i in range(9):\n",
    "        if sum((pred==i))!=0:\n",
    "            pres += sum((pred==i) & ((orig==i) | (orig==i+1) | (orig==i-1))) / sum((pred==i))\n",
    "        rec += sum(((pred==i) | (pred==i-1) | (pred==i+1)) & (orig==i)) / sum((orig==i))\n",
    "    pres = pres/9\n",
    "    rec = rec/9\n",
    "    return 2*pres*rec/(pres+rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Назначаем веса классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexes = list(train.keys())\n",
    "clsw = {8:0.1,7:1,6:1,5:1,4:1,3:1,2:1,1:1,0:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим stateful LSTM модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(120,batch_input_shape=(1, 1, feat_num), stateful=True, dropout_U=0.25, dropout_W=0.25))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(class_num, activation=\"softmax\", init='glorot_uniform'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adagrad')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель, выводя метрики на тестовой выборке, а также на тестовой выборке, давая модели полгода на обучение для каждого банка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(60):\n",
    "    for j in train.keys():\n",
    "        model.fit(train[j],train_y[j], nb_epoch=1, batch_size=1,\n",
    "                  shuffle=False, verbose=0,class_weight=clsw)\n",
    "        model.reset_states()\n",
    "    model.save_weights('models/model'+str(i))\n",
    "    t = 0\n",
    "    for j in test.keys():\n",
    "        if t==0:\n",
    "            pred = model.predict_classes(test[j],batch_size=1,verbose=False)\n",
    "            model.reset_states()\n",
    "            original = test_y[j][:,1]+2*test_y[j][:,2]+3*test_y[j][:,3]+4*test_y[j][:,4]+5*test_y[j][:,5]+6*test_y[j][:,6]+7*test_y[j][:,7]+8*test_y[j][:,8]\n",
    "            pred_mod = pred[6:]\n",
    "            original_mod = original[6:]\n",
    "            t=1\n",
    "            continue\n",
    "        now = model.predict_classes(test[j],batch_size=1,verbose=False)\n",
    "        model.reset_states()\n",
    "        pred = np.hstack((pred,now))\n",
    "        original = np.hstack((original,test_y[j][:,1]+2*test_y[j][:,2]+3*test_y[j][:,3]+4*test_y[j][:,4]+5*test_y[j][:,5]+6*test_y[j][:,6]+7*test_y[j][:,7]+8*test_y[j][:,8]))\n",
    "        if len(now)>6:\n",
    "            pred_mod = np.hstack((pred_mod,now[6:]))\n",
    "            original_mod = np.hstack((original_mod,(test_y[j][:,1]+2*test_y[j][:,2]+3*test_y[j][:,3]+4*test_y[j][:,4]+5*test_y[j][:,5]+6*test_y[j][:,6]+7*test_y[j][:,7]+8*test_y[j][:,8])[6:]))\n",
    "    print((str(i)+'):').ljust(7),str(np.mean(abs(original-pred)))[:6].ljust(9),str(sum(pred==original)/len(pred))[:6].ljust(9),\\\n",
    "         str(fmera(pred,original))[:6].ljust(9),str(fmera_mode(pred,original))[:6].ljust(9))\n",
    "    print((str(i)+'):').ljust(7),str(np.mean(abs(original_mod-pred_mod)))[:6].ljust(9),str(sum(pred_mod==original_mod)/len(pred_mod))[:6].ljust(9),\\\n",
    "         str(fmera(pred_mod,original_mod))[:6].ljust(9),str(fmera_mode(pred_mod,original_mod))[:6].ljust(9),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат, которого удалось достичь - это чистая F1-мера на тестовой выборке в районе 0.35, лояльная F1-мера на тестовой выборке в районе 0.65. В целом опыт интересный и полезный, но тяжело делать подобные проекты в одиночку и за бесплатно. Простора для улучшения результата очень много, однако, он требует времени и сил, но является более рутинной работой."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
